{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_episodes = \"../exploration/BIG_DF_ML.ipynb\"\n",
    "\n",
    "db01 = pd.read_csv(\"../gitignore/title_basics_traite.csv\")\n",
    "db02 = pd.read_csv(\"../gitignore/title_ratings_final.tsv\", sep=\"\\t\")\n",
    "db03 = pd.read_csv(\"../gitignore/title.akas_final.tsv\", sep=\"\\t\")\n",
    "db04 = pd.read_csv(\"../gitignore/tmdb_ml_final.csv\")\n",
    "db05 = pd.read_csv(\"../gitignore/data_bechdel.csv\")\n",
    "db07 = pd.read_csv(\"../gitignore/name.basics.tsv\", sep=\"\\t\") \n",
    "db08 = pd.read_csv(\"../gitignore/title.crew.tsv\", sep=\"\\t\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nconst</th>\n",
       "      <th>primaryName</th>\n",
       "      <th>birthYear</th>\n",
       "      <th>deathYear</th>\n",
       "      <th>primaryProfession</th>\n",
       "      <th>knownForTitles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>nm0000318</td>\n",
       "      <td>Tim Burton</td>\n",
       "      <td>1958</td>\n",
       "      <td>\\N</td>\n",
       "      <td>producer,writer,miscellaneous</td>\n",
       "      <td>tt0099487,tt1142977,tt0121164,tt0408236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        nconst primaryName birthYear deathYear              primaryProfession  \\\n",
       "317  nm0000318  Tim Burton      1958        \\N  producer,writer,miscellaneous   \n",
       "\n",
       "                              knownForTitles  \n",
       "317  tt0099487,tt1142977,tt0121164,tt0408236  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db07[db07['nconst'] == 'nm0000318']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "      <th>directors</th>\n",
       "      <th>writers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>106682</th>\n",
       "      <td>tt0107688</td>\n",
       "      <td>nm0783139</td>\n",
       "      <td>nm0000318,nm0568313,nm0003031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           tconst  directors                        writers\n",
       "106682  tt0107688  nm0783139  nm0000318,nm0568313,nm0003031"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db08[db08['tconst'] == 'tt0107688']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbmerge_1 = pd.merge(db01, db02, right_on='title_ratings_tconst', left_on='tconst', how='left') #Title Basics + Title Ratings\n",
    "dbmerge_2 = pd.merge(dbmerge_1, db03, left_on='tconst', right_on='titleId', how='left') # + Title Akas\n",
    "dbmerge_3 = pd.merge(dbmerge_2, db04, left_on='tconst', right_on='tmdb_imdb_id', how='left') # + TMDB Full\n",
    "dbmerge_4 = pd.merge(dbmerge_3, db05, left_on='tconst', right_on='imdbid', how='left') # + Bechdel\n",
    "dbmerge_4 = pd.merge(dbmerge_4, db08, left_on='tconst', right_on='tconst', how='left') # + Title Crew\n",
    "dbmerge_4 = pd.merge(dbmerge_4, db07, left_on='directors', right_on='nconst', how='left') # + Name Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 688341 entries, 0 to 688340\n",
      "Columns: 117 entries, tconst to knownForTitles\n",
      "dtypes: bool(28), float64(10), int64(3), object(76)\n",
      "memory usage: 485.8+ MB\n"
     ]
    }
   ],
   "source": [
    "dbmerge_4.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dbmerge_4.to_csv(\"../gitignore/BIG_DF_ML.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movie\n",
       "True    688341\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbmerge_4['movie'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIG_DF_ML = dbmerge_4.drop(columns=[\n",
    "    'titleType',\n",
    "    'genres', \n",
    "    'decade', \n",
    "    'Adult',\n",
    "    'Short',\n",
    "    'movie',\n",
    "    'tmdb_Comedy',\n",
    "    'tmdb_Adventure',\n",
    "    'tmdb_Drama',\n",
    "    'tmdb_Crime',\n",
    "    'tmdb_Action',\n",
    "    'tmdb_Documentary',\n",
    "    'tmdb_Animation',\n",
    "    'tmdb_Mystery',\n",
    "    'tmdb_Horror',\n",
    "    'tmdb_Western',\n",
    "    'tmdb_Science Fiction',\n",
    "    'tmdb_Thriller',\n",
    "    'tmdb_Romance',\n",
    "    'tmdb_Fantasy',\n",
    "    'tmdb_Family',\n",
    "    'tmdb_History',\n",
    "    'tmdb_Music',\n",
    "    'tmdb_War', \n",
    "    'ordering',\n",
    "    'region',\n",
    "    'language',\n",
    "    'types',\n",
    "    'attributes',\n",
    "    'isOriginalTitle',\n",
    "    'birthYear',\n",
    "    'deathYear',\n",
    "    'primaryProfession',\n",
    "    'knownForTitles',\n",
    "    'directors',\n",
    "    'writers'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_ratings_tconst</th>\n",
       "      <th>title_ratings_averageRating</th>\n",
       "      <th>tmdb_vote_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688329</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688335</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688336</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688337</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688340</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>357199 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       title_ratings_tconst  title_ratings_averageRating  tmdb_vote_average\n",
       "9                       NaN                          NaN                NaN\n",
       "10                      NaN                          NaN                NaN\n",
       "11                      NaN                          NaN                NaN\n",
       "12                      NaN                          NaN                NaN\n",
       "13                      NaN                          NaN                NaN\n",
       "...                     ...                          ...                ...\n",
       "688329                  NaN                          NaN                NaN\n",
       "688335                  NaN                          NaN                NaN\n",
       "688336                  NaN                          NaN                NaN\n",
       "688337                  NaN                          NaN                NaN\n",
       "688340                  NaN                          NaN                NaN\n",
       "\n",
       "[357199 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BIG_DF_ML.loc[(dbmerge_4['title_ratings_averageRating'].isnull())&(dbmerge_4['tmdb_vote_average'].isnull()), ['title_ratings_tconst', 'title_ratings_averageRating', 'tmdb_vote_average']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIG_DF_ML3 = BIG_DF_ML.dropna(subset=['title_ratings_averageRating','tmdb_vote_average'],how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frale\\AppData\\Local\\Temp\\ipykernel_17420\\2696331554.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  BIG_DF_ML3['notes'] = BIG_DF_ML3.apply(moyenne_ponderee, axis=1)\n"
     ]
    }
   ],
   "source": [
    "def moyenne_ponderee(ligne):\n",
    "\n",
    "    # Si 'title_ratings_averageRating' est NaN, on ne prend que 'tmdb_vote_average', et vice versa\n",
    "\n",
    "    if pd.isna(ligne['title_ratings_averageRating']) and not pd.isna(ligne['tmdb_vote_average']):\n",
    "        return ligne['tmdb_vote_average']  # Si title_ratings_averageRating est vide, prendre tmdb_vote_average\n",
    "\n",
    "    elif pd.isna(ligne['tmdb_vote_average']) and not pd.isna(ligne['title_ratings_averageRating']):\n",
    "        return ligne['title_ratings_averageRating']  # Si tmdb_vote_average est vide, prendre title_ratings_averageRating\n",
    "\n",
    "    elif not pd.isna(ligne['title_ratings_averageRating']) and not pd.isna(ligne['tmdb_vote_average']):\n",
    "        # Si les deux colonnes ont des valeurs, calculer la moyenne pondérée\n",
    "        return (ligne['title_ratings_averageRating'] * ligne['title_ratings_numVotes'] + ligne['tmdb_vote_average'] * ligne['tmdb_vote_count']) / (ligne['title_ratings_numVotes'] + ligne['tmdb_vote_count'])  # Moyenne simple, à ajuster si besoin !\n",
    "    else:\n",
    "        return np.nan  # Si les deux sont NaN, retourner NaN\n",
    "\n",
    "\n",
    "BIG_DF_ML3['notes'] = BIG_DF_ML3.apply(moyenne_ponderee, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIG_DF_ML4 = BIG_DF_ML3.drop(['title_ratings_averageRating','tmdb_vote_average','title_ratings_tconst','titleId','tmdb_imdb_id','imdbid', 'primaryName'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def startyear(ligne):\n",
    "\n",
    "    # Si 'start year' est 0, il prend la valeur 'tmbd release date'\n",
    "    BIG_DF_ML4.loc[(BIG_DF_ML4['startYear'] == 0)&(BIG_DF_ML4['tmdb_release_date'] != 0), 'startYear'] = BIG_DF_ML4['tmdb_release_date']\n",
    "\n",
    "startyear(BIG_DF_ML4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def release_date(ligne):\n",
    "\n",
    "    # Si 'tmdn release date' est 0, il prend la valeur 'start year'\n",
    "    BIG_DF_ML4.loc[(BIG_DF_ML4['tmdb_release_date'] == 0)&(BIG_DF_ML4['startYear'] != 0), 'tmdb_release_date'] = BIG_DF_ML4['startYear']\n",
    "\n",
    "release_date(BIG_DF_ML4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def release_date(ligne):\n",
    "\n",
    "    # Si 'tmdn release date' est 0, il prend la valeur 'start year'\n",
    "    BIG_DF_ML4.loc[(BIG_DF_ML4['tmdb_release_date'].isna())&(BIG_DF_ML4['startYear'] != 0), 'tmdb_release_date'] = BIG_DF_ML4['startYear']\n",
    "\n",
    "release_date(BIG_DF_ML4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runtimeMinutes(ligne):\n",
    "\n",
    "    # Si 'runtimeMinutes' est 0, il prend la valeur 'tmdb_runtime'\n",
    "    BIG_DF_ML4.loc[(BIG_DF_ML4['runtimeMinutes'] == 0)&(BIG_DF_ML4['tmdb_runtime'] != 0), 'runtimeMinutes'] = BIG_DF_ML4['tmdb_runtime']\n",
    "\n",
    "runtimeMinutes(BIG_DF_ML4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runtimeMinutes(ligne):\n",
    "\n",
    "    # Si 'tmdb_runtime' est 0, il prend la valeur 'runtimeMinutes'\n",
    "    BIG_DF_ML4.loc[(BIG_DF_ML4['tmdb_runtime'] == 0)&(BIG_DF_ML4['runtimeMinutes'] != 0), 'tmdb_runtime'] = BIG_DF_ML4['runtimeMinutes']\n",
    "\n",
    "runtimeMinutes(BIG_DF_ML4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frale\\AppData\\Local\\Temp\\ipykernel_17420\\2379037837.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  BIG_DF_ML4[BIG_DF_ML4['startYear']==0] = np.nan\n",
      "C:\\Users\\frale\\AppData\\Local\\Temp\\ipykernel_17420\\2379037837.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  BIG_DF_ML4[BIG_DF_ML4['startYear']==0] = np.nan\n",
      "C:\\Users\\frale\\AppData\\Local\\Temp\\ipykernel_17420\\2379037837.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  BIG_DF_ML4[BIG_DF_ML4['startYear']==0] = np.nan\n",
      "C:\\Users\\frale\\AppData\\Local\\Temp\\ipykernel_17420\\2379037837.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  BIG_DF_ML4[BIG_DF_ML4['startYear']==0] = np.nan\n",
      "C:\\Users\\frale\\AppData\\Local\\Temp\\ipykernel_17420\\2379037837.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  BIG_DF_ML4[BIG_DF_ML4['startYear']==0] = np.nan\n",
      "C:\\Users\\frale\\AppData\\Local\\Temp\\ipykernel_17420\\2379037837.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  BIG_DF_ML4[BIG_DF_ML4['startYear']==0] = np.nan\n",
      "C:\\Users\\frale\\AppData\\Local\\Temp\\ipykernel_17420\\2379037837.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  BIG_DF_ML4[BIG_DF_ML4['startYear']==0] = np.nan\n",
      "C:\\Users\\frale\\AppData\\Local\\Temp\\ipykernel_17420\\2379037837.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  BIG_DF_ML4[BIG_DF_ML4['startYear']==0] = np.nan\n",
      "C:\\Users\\frale\\AppData\\Local\\Temp\\ipykernel_17420\\2379037837.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  BIG_DF_ML4[BIG_DF_ML4['startYear']==0] = np.nan\n",
      "C:\\Users\\frale\\AppData\\Local\\Temp\\ipykernel_17420\\2379037837.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  BIG_DF_ML4[BIG_DF_ML4['startYear']==0] = np.nan\n",
      "C:\\Users\\frale\\AppData\\Local\\Temp\\ipykernel_17420\\2379037837.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  BIG_DF_ML4[BIG_DF_ML4['startYear']==0] = np.nan\n",
      "C:\\Users\\frale\\AppData\\Local\\Temp\\ipykernel_17420\\2379037837.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  BIG_DF_ML4[BIG_DF_ML4['startYear']==0] = np.nan\n",
      "C:\\Users\\frale\\AppData\\Local\\Temp\\ipykernel_17420\\2379037837.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  BIG_DF_ML4[BIG_DF_ML4['startYear']==0] = np.nan\n",
      "C:\\Users\\frale\\AppData\\Local\\Temp\\ipykernel_17420\\2379037837.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  BIG_DF_ML4[BIG_DF_ML4['startYear']==0] = np.nan\n",
      "C:\\Users\\frale\\AppData\\Local\\Temp\\ipykernel_17420\\2379037837.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  BIG_DF_ML4[BIG_DF_ML4['startYear']==0] = np.nan\n",
      "C:\\Users\\frale\\AppData\\Local\\Temp\\ipykernel_17420\\2379037837.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  BIG_DF_ML4[BIG_DF_ML4['startYear']==0] = np.nan\n",
      "C:\\Users\\frale\\AppData\\Local\\Temp\\ipykernel_17420\\2379037837.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  BIG_DF_ML4[BIG_DF_ML4['startYear']==0] = np.nan\n",
      "C:\\Users\\frale\\AppData\\Local\\Temp\\ipykernel_17420\\2379037837.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  BIG_DF_ML4[BIG_DF_ML4['startYear']==0] = np.nan\n",
      "C:\\Users\\frale\\AppData\\Local\\Temp\\ipykernel_17420\\2379037837.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  BIG_DF_ML4[BIG_DF_ML4['startYear']==0] = np.nan\n",
      "C:\\Users\\frale\\AppData\\Local\\Temp\\ipykernel_17420\\2379037837.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  BIG_DF_ML4[BIG_DF_ML4['startYear']==0] = np.nan\n",
      "C:\\Users\\frale\\AppData\\Local\\Temp\\ipykernel_17420\\2379037837.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  BIG_DF_ML4[BIG_DF_ML4['startYear']==0] = np.nan\n",
      "C:\\Users\\frale\\AppData\\Local\\Temp\\ipykernel_17420\\2379037837.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  BIG_DF_ML4[BIG_DF_ML4['startYear']==0] = np.nan\n",
      "C:\\Users\\frale\\AppData\\Local\\Temp\\ipykernel_17420\\2379037837.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  BIG_DF_ML4[BIG_DF_ML4['startYear']==0] = np.nan\n",
      "C:\\Users\\frale\\AppData\\Local\\Temp\\ipykernel_17420\\2379037837.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  BIG_DF_ML4[BIG_DF_ML4['startYear']==0] = np.nan\n",
      "C:\\Users\\frale\\AppData\\Local\\Temp\\ipykernel_17420\\2379037837.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  BIG_DF_ML4[BIG_DF_ML4['startYear']==0] = np.nan\n"
     ]
    }
   ],
   "source": [
    "#On transforme les valeurs 0 en NaN pour les supprimer ensuite\n",
    "import numpy as np\n",
    "BIG_DF_ML4[BIG_DF_ML4['startYear']==0] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On transforme les valeurs 0 en NaN pour les supprimer ensuite\n",
    "BIG_DF_ML4[BIG_DF_ML4['runtimeMinutes']==0] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIG_DF_ML5 = BIG_DF_ML4.drop(columns =['tmdb_runtime','tmdb_release_date','tmdb_original_title','tmdb_title','tmdb_vote_count','tmdb_TV Movie'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIG_DF_ML5 = BIG_DF_ML5.dropna(subset=['runtimeMinutes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIG_DF_ML5 = BIG_DF_ML5.dropna(subset=['startYear'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIG_DF_ML5 = BIG_DF_ML5.dropna(subset=['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frale\\AppData\\Local\\Temp\\ipykernel_17420\\61637864.py:9: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  BIG_DF_ML5[Remplacer] = BIG_DF_ML5[Remplacer].fillna(False)\n"
     ]
    }
   ],
   "source": [
    "# Pour notre ML, on remplace toutes les valeurs nulles des pays de production par False \n",
    "Remplacer = [\n",
    "    'tmdb_US', 'tmdb_FR', 'tmdb_GB', 'tmdb_DE', 'tmdb_JP', 'tmdb_IN', 'tmdb_IT',\n",
    "    'tmdb_CA', 'tmdb_ES', 'tmdb_MX', 'tmdb_HK', 'tmdb_BR', 'tmdb_SE', 'tmdb_SU',\n",
    "    'tmdb_PH', 'tmdb_KR', 'tmdb_AU', 'tmdb_CN', 'tmdb_AR', 'tmdb_RU', 'tmdb_DK',\n",
    "    'tmdb_NL', 'tmdb_BE', 'tmdb_AT', 'tmdb_TR', 'tmdb_PL', 'tmdb_CH', 'tmdb_XC',\n",
    "    'tmdb_FI', 'tmdb_NO', 'tmdb_IR', 'tmdb_XG', 'tmdb_EG', 'tmdb_NG', 'tmdb_ZA'\n",
    "]\n",
    "BIG_DF_ML5[Remplacer] = BIG_DF_ML5[Remplacer].fillna(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIG_DF_ML5['rating'] = BIG_DF_ML5['rating'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIG_DF_ML5['title_ratings_numVotes'] = BIG_DF_ML5['title_ratings_numVotes'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIG_DF_ML5['tmdb_popularity'] = BIG_DF_ML5['tmdb_popularity'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIG_DF_ML5['nconst'] = BIG_DF_ML5['nconst'].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIG_DF_ML5[['Action', 'Adventure',\n",
    "       'Animation', 'Biography', 'Comedy', 'Crime', 'Documentary', 'Drama',\n",
    "       'Family', 'Fantasy', 'Game-Show', 'History', 'Horror', 'Music',\n",
    "       'Musical', 'Mystery', 'News', 'Reality-TV', 'Romance', 'Sci-Fi',\n",
    "       'Sport', 'Talk-Show', 'Thriller', 'War', 'Western']] = BIG_DF_ML5[['Action', 'Adventure',\n",
    "       'Animation', 'Biography', 'Comedy', 'Crime', 'Documentary', 'Drama',\n",
    "       'Family', 'Fantasy', 'Game-Show', 'History', 'Horror', 'Music',\n",
    "       'Musical', 'Mystery', 'News', 'Reality-TV', 'Romance', 'Sci-Fi',\n",
    "       'Sport', 'Talk-Show', 'Thriller', 'War', 'Western']].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "export = \"../machine learning/DF_ML.csv.gz\"\n",
    "BIG_DF_ML5.to_csv(export, sep=\",\", index=False, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml = BIG_DF_ML5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test de ML avec cible sur les notes > 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 301086 entries, 0 to 688339\n",
      "Data columns (total 69 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   tconst                  301086 non-null  object \n",
      " 1   startYear               301086 non-null  float64\n",
      " 2   runtimeMinutes          301086 non-null  float64\n",
      " 3   Action                  301086 non-null  bool   \n",
      " 4   Adventure               301086 non-null  bool   \n",
      " 5   Animation               301086 non-null  bool   \n",
      " 6   Biography               301086 non-null  bool   \n",
      " 7   Comedy                  301086 non-null  bool   \n",
      " 8   Crime                   301086 non-null  bool   \n",
      " 9   Documentary             301086 non-null  bool   \n",
      " 10  Drama                   301086 non-null  bool   \n",
      " 11  Family                  301086 non-null  bool   \n",
      " 12  Fantasy                 301086 non-null  bool   \n",
      " 13  Game-Show               301086 non-null  bool   \n",
      " 14  History                 301086 non-null  bool   \n",
      " 15  Horror                  301086 non-null  bool   \n",
      " 16  Music                   301086 non-null  bool   \n",
      " 17  Musical                 301086 non-null  bool   \n",
      " 18  Mystery                 301086 non-null  bool   \n",
      " 19  News                    301086 non-null  bool   \n",
      " 20  Reality-TV              301086 non-null  bool   \n",
      " 21  Romance                 301086 non-null  bool   \n",
      " 22  Sci-Fi                  301086 non-null  bool   \n",
      " 23  Sport                   301086 non-null  bool   \n",
      " 24  Talk-Show               301086 non-null  bool   \n",
      " 25  Thriller                301086 non-null  bool   \n",
      " 26  War                     301086 non-null  bool   \n",
      " 27  Western                 301086 non-null  bool   \n",
      " 28  title_ratings_numVotes  301086 non-null  float64\n",
      " 29  title                   301086 non-null  object \n",
      " 30  tmdb_popularity         301086 non-null  float64\n",
      " 31  tmdb_US                 301086 non-null  bool   \n",
      " 32  tmdb_FR                 301086 non-null  bool   \n",
      " 33  tmdb_GB                 301086 non-null  bool   \n",
      " 34  tmdb_DE                 301086 non-null  bool   \n",
      " 35  tmdb_JP                 301086 non-null  bool   \n",
      " 36  tmdb_IN                 301086 non-null  bool   \n",
      " 37  tmdb_IT                 301086 non-null  bool   \n",
      " 38  tmdb_CA                 301086 non-null  bool   \n",
      " 39  tmdb_ES                 301086 non-null  bool   \n",
      " 40  tmdb_MX                 301086 non-null  bool   \n",
      " 41  tmdb_HK                 301086 non-null  bool   \n",
      " 42  tmdb_BR                 301086 non-null  bool   \n",
      " 43  tmdb_SE                 301086 non-null  bool   \n",
      " 44  tmdb_SU                 301086 non-null  bool   \n",
      " 45  tmdb_PH                 301086 non-null  bool   \n",
      " 46  tmdb_KR                 301086 non-null  bool   \n",
      " 47  tmdb_AU                 301086 non-null  bool   \n",
      " 48  tmdb_CN                 301086 non-null  bool   \n",
      " 49  tmdb_AR                 301086 non-null  bool   \n",
      " 50  tmdb_RU                 301086 non-null  bool   \n",
      " 51  tmdb_DK                 301086 non-null  bool   \n",
      " 52  tmdb_NL                 301086 non-null  bool   \n",
      " 53  tmdb_BE                 301086 non-null  bool   \n",
      " 54  tmdb_AT                 301086 non-null  bool   \n",
      " 55  tmdb_TR                 301086 non-null  bool   \n",
      " 56  tmdb_PL                 301086 non-null  bool   \n",
      " 57  tmdb_CH                 301086 non-null  bool   \n",
      " 58  tmdb_XC                 301086 non-null  bool   \n",
      " 59  tmdb_FI                 301086 non-null  bool   \n",
      " 60  tmdb_NO                 301086 non-null  bool   \n",
      " 61  tmdb_IR                 301086 non-null  bool   \n",
      " 62  tmdb_XG                 301086 non-null  bool   \n",
      " 63  tmdb_EG                 301086 non-null  bool   \n",
      " 64  tmdb_NG                 301086 non-null  bool   \n",
      " 65  tmdb_ZA                 301086 non-null  bool   \n",
      " 66  rating                  301086 non-null  float64\n",
      " 67  nconst                  301086 non-null  object \n",
      " 68  notes                   301086 non-null  float64\n",
      "dtypes: bool(60), float64(6), object(3)\n",
      "memory usage: 40.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_ml.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           tconst  startYear  runtimeMinutes  Action  Adventure  Animation  \\\n",
      "8       tt0000679     1908.0           120.0   False       True      False   \n",
      "20      tt0000941     1909.0            45.0   False      False      False   \n",
      "50      tt0001184     1910.0            58.0   False       True      False   \n",
      "82      tt0001614     1911.0            60.0   False      False      False   \n",
      "113     tt0002031     1912.0            33.0   False      False      False   \n",
      "...           ...        ...             ...     ...        ...        ...   \n",
      "688116  tt9904250     2019.0            63.0   False      False      False   \n",
      "688125  tt9904648     2022.0            82.0   False      False      False   \n",
      "688144  tt9905476     2019.0            90.0   False      False      False   \n",
      "688288  tt9914368     2019.0           115.0    True      False      False   \n",
      "688303  tt9914972     2021.0            96.0   False      False      False   \n",
      "\n",
      "        Biography  Comedy  Crime  Documentary  ...  tmdb_FI  tmdb_NO  tmdb_IR  \\\n",
      "8           False   False  False        False  ...    False    False    False   \n",
      "20          False   False  False        False  ...    False    False    False   \n",
      "50          False   False  False        False  ...    False    False    False   \n",
      "82          False   False  False        False  ...    False    False    False   \n",
      "113         False   False  False        False  ...    False    False    False   \n",
      "...           ...     ...    ...          ...  ...      ...      ...      ...   \n",
      "688116      False   False  False        False  ...    False    False    False   \n",
      "688125      False    True  False        False  ...    False    False    False   \n",
      "688144      False   False  False         True  ...    False    False    False   \n",
      "688288      False   False   True        False  ...    False    False    False   \n",
      "688303      False   False  False         True  ...    False    False    False   \n",
      "\n",
      "        tmdb_XG  tmdb_EG  tmdb_NG  tmdb_ZA  rating  nconst     notes  \n",
      "8         False    False    False    False     0.0          5.200000  \n",
      "20        False    False    False    False     0.0          4.600000  \n",
      "50        False    False    False    False     0.0          3.678261  \n",
      "82        False    False    False    False     0.0          6.500000  \n",
      "113       False    False    False    False     0.0          4.365385  \n",
      "...         ...      ...      ...      ...     ...     ...       ...  \n",
      "688116    False    False    False    False     0.0          4.851739  \n",
      "688125    False    False    False    False     0.0          4.069444  \n",
      "688144    False    False    False    False     0.0          7.947500  \n",
      "688288    False    False    False    False     0.0          0.000000  \n",
      "688303    False    False    False    False     0.0          7.107837  \n",
      "\n",
      "[44415 rows x 69 columns]\n"
     ]
    }
   ],
   "source": [
    "# Obtenir les fréquences des valeurs uniques dans la colonne 'nconst'\n",
    "counts = df_ml['nconst'].value_counts()\n",
    "\n",
    "# Filtrer les valeurs qui apparaissent plus de 20 fois\n",
    "valid_nconst = counts[counts > 50].index\n",
    "\n",
    "# Garder uniquement les lignes où 'nconst' est dans valid_nconst\n",
    "filtered_df = df_ml[df_ml['nconst'].isin(valid_nconst)]\n",
    "\n",
    "# Résultat\n",
    "print(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103218"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ml2 = df_ml[df_ml['startYear']>1920]\n",
    "df_ml2['nconst'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On veut entrainer notre modèle sur tout le dataframe et afficher UNIQUEMENT les k films les plus proches dont les notes sont supérieures à 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommandation(tconst):\n",
    "\n",
    "     df_ml = pd.read_csv(\"../machine learning/DF_ML.csv.gz\")\n",
    "\n",
    "     index = df_ml.index\n",
    "     df_ml_num = df_ml.select_dtypes('number')\n",
    "     df_ml_cat = df_ml.select_dtypes(['object', 'category', 'string', 'bool'])\n",
    "\n",
    "     from sklearn.preprocessing import MinMaxScaler\n",
    "     SN = MinMaxScaler()\n",
    "     df_ml_num_SN = pd.DataFrame(SN.fit_transform(df_ml_num), columns=df_ml_num.columns, index=index)\n",
    "\n",
    "     df_ml_encoded = pd.concat([df_ml_num_SN, df_ml_cat], axis=1)\n",
    "\n",
    "     #On crée une liste des colonnes à utiliser pour le modèle\n",
    "     caracteristiques = df_ml_encoded.columns.drop(['tconst', 'nconst', 'title', 'tmdb_popularity', 'title_ratings_numVotes','tmdb_US',\n",
    "          'tmdb_FR', 'tmdb_GB', 'tmdb_DE', 'tmdb_JP', 'tmdb_IN', 'tmdb_IT',\n",
    "          'tmdb_CA', 'tmdb_ES', 'tmdb_MX', 'tmdb_HK', 'tmdb_BR', 'tmdb_SE',\n",
    "          'tmdb_SU', 'tmdb_PH', 'tmdb_KR', 'tmdb_AU', 'tmdb_CN', 'tmdb_AR',\n",
    "          'tmdb_RU', 'tmdb_DK', 'tmdb_NL', 'tmdb_BE', 'tmdb_AT', 'tmdb_TR',\n",
    "          'tmdb_PL', 'tmdb_CH', 'tmdb_XC', 'tmdb_FI', 'tmdb_NO', 'tmdb_IR',\n",
    "          'tmdb_XG', 'tmdb_EG', 'tmdb_NG', 'tmdb_ZA'])\n",
    "\n",
    "     #On sépare notre df en deux groupes, en fonction de la note\n",
    "     bons_films = df_ml_encoded[df_ml_encoded['notes'] >= 0.7]\n",
    "     mauvais_films = df_ml_encoded[df_ml_encoded['notes'] < 0.7]\n",
    "\n",
    "     #On crée notre modèle\n",
    "     model = NearestNeighbors(n_neighbors=1000, metric='euclidean')\n",
    "     model.fit(bons_films[caracteristiques])\n",
    "\n",
    "     #On déclare les caractéristiques du film sélectionné par l'utilisateur\n",
    "     caract_film = df_ml_encoded[df_ml_encoded['tconst'] == tconst]\n",
    "     caract_film = caract_film[caracteristiques]\n",
    "     caract_film\n",
    "\n",
    "     distances, indices = model.kneighbors(caract_film)\n",
    "\n",
    "     #On affiche la selection des films en fonction des indices trouvés par le modèle\n",
    "     if caract_film['notes'].values[0] > 0.7:\n",
    "          distances = distances[0][1:11]\n",
    "          indices = indices[0][1:11]\n",
    "          selection = bons_films.iloc[indices]['tconst']\n",
    "     else:\n",
    "          distances = distances[0][0:10]\n",
    "          indices = indices[0][0:10]\n",
    "          selection = bons_films.iloc[indices]['tconst']\n",
    "\n",
    "     return selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56355</th>\n",
       "      <td>tt0099653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125111</th>\n",
       "      <td>tt0421715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169677</th>\n",
       "      <td>tt1368491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189246</th>\n",
       "      <td>tt1655441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267928</th>\n",
       "      <td>tt5580390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16838</th>\n",
       "      <td>tt0038348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16369</th>\n",
       "      <td>tt0037671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46018</th>\n",
       "      <td>tt0081534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19208</th>\n",
       "      <td>tt0041719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66256</th>\n",
       "      <td>tt0119643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           tconst\n",
       "56355   tt0099653\n",
       "125111  tt0421715\n",
       "169677  tt1368491\n",
       "189246  tt1655441\n",
       "267928  tt5580390\n",
       "16838   tt0038348\n",
       "16369   tt0037671\n",
       "46018   tt0081534\n",
       "19208   tt0041719\n",
       "66256   tt0119643"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selection = recommandation('tt0099487')\n",
    "pd.DataFrame(selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nweights = X_encoded[['Action', 'Adventure',\\n       'Animation', 'Biography', 'Comedy', 'Crime', 'Documentary', 'Drama',\\n       'Family', 'Fantasy', 'Game-Show', 'History', 'Horror', 'Music',\\n       'Musical', 'Mystery', 'News', 'Reality-TV', 'Romance', 'Sci-Fi',\\n       'Sport', 'Talk-Show', 'Thriller', 'War', 'Western']].astype(bool)\\nweights *= 2\\nX_weighted = pd.concat([weights, X_encoded.drop(columns = ['Action', 'Adventure',\\n       'Animation', 'Biography', 'Comedy', 'Crime', 'Documentary', 'Drama',\\n       'Family', 'Fantasy', 'Game-Show', 'History', 'Horror', 'Music',\\n       'Musical', 'Mystery', 'News', 'Reality-TV', 'Romance', 'Sci-Fi',\\n       'Sport', 'Talk-Show', 'Thriller', 'War', 'Western'])], axis=1)\\n\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "weights = X_encoded[['Action', 'Adventure',\n",
    "       'Animation', 'Biography', 'Comedy', 'Crime', 'Documentary', 'Drama',\n",
    "       'Family', 'Fantasy', 'Game-Show', 'History', 'Horror', 'Music',\n",
    "       'Musical', 'Mystery', 'News', 'Reality-TV', 'Romance', 'Sci-Fi',\n",
    "       'Sport', 'Talk-Show', 'Thriller', 'War', 'Western']].astype(bool)\n",
    "weights *= 2\n",
    "X_weighted = pd.concat([weights, X_encoded.drop(columns = ['Action', 'Adventure',\n",
    "       'Animation', 'Biography', 'Comedy', 'Crime', 'Documentary', 'Drama',\n",
    "       'Family', 'Fantasy', 'Game-Show', 'History', 'Horror', 'Music',\n",
    "       'Musical', 'Mystery', 'News', 'Reality-TV', 'Romance', 'Sci-Fi',\n",
    "       'Sport', 'Talk-Show', 'Thriller', 'War', 'Western'])], axis=1)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test ML avec TF_IDF (sans les poids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frale\\AppData\\Local\\Temp\\ipykernel_17420\\3263337905.py:1: DtypeWarning: Columns (24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  tmdb = pd.read_csv(\"../gitignore/tmdb_full.csv\")\n"
     ]
    }
   ],
   "source": [
    "tmdb = pd.read_csv(\"../gitignore/tmdb_full.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmdb = tmdb[['imdb_id', 'genres', 'overview']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.merge(left=df_ml, right=tmdb, how='left', left_on='tconst', right_on='imdb_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommandation2(tconst):\n",
    "\n",
    "     index = df_test.index\n",
    "     df_test_num = df_test.select_dtypes('number')\n",
    "     df_test_cat = df_test.select_dtypes(['object', 'category', 'string', 'bool'])\n",
    "\n",
    "     from sklearn.preprocessing import MinMaxScaler\n",
    "     SN = MinMaxScaler()\n",
    "     df_test_num_SN = pd.DataFrame(SN.fit_transform(df_test_num), columns=df_test_num.columns, index=index)\n",
    "\n",
    "     df_test_encoded = pd.concat([df_test_num_SN, df_test_cat], axis=1)\n",
    "\n",
    "     #On crée une liste des colonnes à utiliser pour le modèle\n",
    "     caracteristiques = df_test_encoded.columns.drop(['tconst', 'nconst', 'title', 'tmdb_popularity', \n",
    "                                                      'title_ratings_numVotes', 'imdb_id', 'genres', 'overview', 'tmdb_US',\n",
    "          'tmdb_FR', 'tmdb_GB', 'tmdb_DE', 'tmdb_JP', 'tmdb_IN', 'tmdb_IT',\n",
    "          'tmdb_CA', 'tmdb_ES', 'tmdb_MX', 'tmdb_HK', 'tmdb_BR', 'tmdb_SE',\n",
    "          'tmdb_SU', 'tmdb_PH', 'tmdb_KR', 'tmdb_AU', 'tmdb_CN', 'tmdb_AR',\n",
    "          'tmdb_RU', 'tmdb_DK', 'tmdb_NL', 'tmdb_BE', 'tmdb_AT', 'tmdb_TR',\n",
    "          'tmdb_PL', 'tmdb_CH', 'tmdb_XC', 'tmdb_FI', 'tmdb_NO', 'tmdb_IR',\n",
    "          'tmdb_XG', 'tmdb_EG', 'tmdb_NG', 'tmdb_ZA'])\n",
    "\n",
    "     #On sépare notre df en deux groupes, en fonction de la note\n",
    "     bons_films = df_test_encoded[df_test_encoded['notes'] >= 0.7]\n",
    "     mauvais_films = df_test_encoded[df_test_encoded['notes'] < 0.7]\n",
    "\n",
    "     #On crée notre modèle\n",
    "     model = NearestNeighbors(n_neighbors=1000, metric='euclidean')\n",
    "     model.fit(bons_films[caracteristiques])\n",
    "\n",
    "     #On déclare les caractéristiques du film sélectionné par l'utilisateur\n",
    "     caract_film = df_test_encoded[df_test_encoded['tconst'] == tconst]\n",
    "     caract_film = caract_film[caracteristiques]\n",
    "     caract_film\n",
    "\n",
    "     distances, indices = model.kneighbors(caract_film)\n",
    "\n",
    "     #On affiche la selection des films en fonction des indices trouvés par le modèle\n",
    "     colonnes = ['tconst', 'genres', 'overview', 'nconst']  # Liste à étendre si besoin\n",
    "     selection = bons_films.iloc[indices[0]][colonnes]\n",
    "     df_selection = pd.DataFrame(selection).reset_index()\n",
    "\n",
    "     #On crée un nouveau df à partir des données textuelles pour l'étudier avec TF-IDF\n",
    "     df_tfidf = df_selection.copy()\n",
    "     df_tfidf['texte'] = df_selection[colonnes].fillna('').agg(' '.join, axis=1)\n",
    "     df_tfidf = pd.DataFrame(df_tfidf['texte'], columns=['texte'])\n",
    "\n",
    "     from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "     from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "     #Limite aux 100 mots les plus présents et supprime les mots contenus dans plus de 80% des lignes\n",
    "     vectorizer = TfidfVectorizer(stop_words='english', max_df=0.8, max_features=100)\n",
    "     df_tfidf = vectorizer.fit_transform(df_tfidf['texte'])\n",
    "\n",
    "     #On calcule la distance entre chaque vecteur\n",
    "     similarite = cosine_similarity(df_tfidf)\n",
    "\n",
    "     #On crée une liste de tuple avec un index et le score de similarite par rapport au film cible (index 0 car première ligne)\n",
    "     film_index = df_selection.index[0]\n",
    "     similarity_scores = list(enumerate(similarite[film_index]))\n",
    "\n",
    "     #On trie le résultat par rapport aux scores et par ordre decroissant en ignorant la partie index (key permet de cibler uniquement le score)\n",
    "     similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "     similar_movies = [df_selection['tconst'].iloc[i[0]] for i in similarity_scores[1:10]]\n",
    "\n",
    "     return similar_movies\n",
    "\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tt0120334',\n",
       " 'tt2905772',\n",
       " 'tt0041373',\n",
       " 'tt0054005',\n",
       " 'tt0345425',\n",
       " 'tt0241303',\n",
       " 'tt0213847',\n",
       " 'tt0098384',\n",
       " 'tt0029608']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selection2 = recommandation2('tt0099487')\n",
    "selection2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test ML avec TF_IDF (avec les poids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommandation2(tconst):\n",
    "\n",
    "     index = df_test.index\n",
    "     df_test_num = df_test.select_dtypes('number')\n",
    "     df_test_cat = df_test.select_dtypes(['object', 'category', 'string', 'bool'])\n",
    "\n",
    "     from sklearn.preprocessing import MinMaxScaler\n",
    "     SN = MinMaxScaler()\n",
    "     df_test_num_SN = pd.DataFrame(SN.fit_transform(df_test_num), columns=df_test_num.columns, index=index)\n",
    "\n",
    "     df_test_encoded = pd.concat([df_test_num_SN, df_test_cat], axis=1)\n",
    "\n",
    "     #On crée une liste des colonnes à utiliser pour le modèle\n",
    "     caracteristiques = df_test_encoded.columns.drop(['tconst', 'nconst', 'title', 'tmdb_popularity', \n",
    "                                                      'title_ratings_numVotes', 'imdb_id', 'genres', 'overview', 'tmdb_US',\n",
    "          'tmdb_FR', 'tmdb_GB', 'tmdb_DE', 'tmdb_JP', 'tmdb_IN', 'tmdb_IT',\n",
    "          'tmdb_CA', 'tmdb_ES', 'tmdb_MX', 'tmdb_HK', 'tmdb_BR', 'tmdb_SE',\n",
    "          'tmdb_SU', 'tmdb_PH', 'tmdb_KR', 'tmdb_AU', 'tmdb_CN', 'tmdb_AR',\n",
    "          'tmdb_RU', 'tmdb_DK', 'tmdb_NL', 'tmdb_BE', 'tmdb_AT', 'tmdb_TR',\n",
    "          'tmdb_PL', 'tmdb_CH', 'tmdb_XC', 'tmdb_FI', 'tmdb_NO', 'tmdb_IR',\n",
    "          'tmdb_XG', 'tmdb_EG', 'tmdb_NG', 'tmdb_ZA'])\n",
    "\n",
    "     #On sépare notre df en deux groupes, en fonction de la note\n",
    "     bons_films = df_test_encoded[df_test_encoded['notes'] >= 0.7]\n",
    "     mauvais_films = df_test_encoded[df_test_encoded['notes'] < 0.7]\n",
    "\n",
    "     #On crée notre modèle\n",
    "     model = NearestNeighbors(n_neighbors=1000, metric='euclidean')\n",
    "     model.fit(bons_films[caracteristiques])\n",
    "\n",
    "     #On déclare les caractéristiques du film sélectionné par l'utilisateur\n",
    "     caract_film = df_test_encoded[df_test_encoded['tconst'] == tconst]\n",
    "     caract_film = caract_film[caracteristiques]\n",
    "     caract_film\n",
    "\n",
    "     distances, indices = model.kneighbors(caract_film)\n",
    "\n",
    "     #On affiche la selection des films en fonction des indices trouvés par le modèle\n",
    "     colonnes = ['tconst', 'genres', 'overview', 'nconst']  # Liste à étendre si besoin\n",
    "     selection = bons_films.iloc[indices[0]][colonnes]\n",
    "     df_selection = pd.DataFrame(selection).reset_index()\n",
    "\n",
    "     #On crée une colonne pour identifier le réalisateur s'il correspond à celui du film cible\n",
    "     cible_real = df_test.loc[df_test['tconst'] == tconst, 'nconst']\n",
    "     df_selection['real_identique'] = df_selection['nconst'].apply(\n",
    "        lambda x: 1 if x in cible_real else 0\n",
    "     )\n",
    "\n",
    "     #On définit les poids pour chaque colonne textuelle\n",
    "     colonnes_poids = {\n",
    "        'tconst': 1,\n",
    "        'genres': 1,\n",
    "        'overview': 1,\n",
    "        'nconst': 20,\n",
    "        'real_identique': 100\n",
    "     }\n",
    "\n",
    "     #On crée une colonne 'texte' pondérée dynamiquement\n",
    "     df_tfidf = df_selection.copy()\n",
    "     df_tfidf['texte'] = df_selection.apply(\n",
    "     lambda ligne: ' '.join(\n",
    "          (str(ligne[col]) + ' ') * poids for col, poids in colonnes_poids.items()\n",
    "     ),\n",
    "     axis=1\n",
    "     )\n",
    "\n",
    "     #On crée le DataFrame final pour TF-IDF\n",
    "     df_tfidf = pd.DataFrame(df_tfidf['texte'], columns=['texte'])\n",
    "\n",
    "     from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "     from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "     #Limite aux 100 mots les plus présents et supprime les mots contenus dans plus de 80% des lignes\n",
    "     vectorizer = TfidfVectorizer(stop_words='english', max_df=0.8)\n",
    "     df_tfidf = vectorizer.fit_transform(df_tfidf['texte'])\n",
    "\n",
    "     #On calcule la distance entre chaque vecteur\n",
    "     similarite = cosine_similarity(df_tfidf)\n",
    "\n",
    "     #On crée une liste de tuple avec un index et le score de similarite par rapport au film cible (index 0 car première ligne)\n",
    "     film_index = df_selection.index[0]\n",
    "     similarity_scores = list(enumerate(similarite[film_index]))\n",
    "\n",
    "     #On trie le résultat par rapport aux scores et par ordre decroissant en ignorant la partie index (key permet de cibler uniquement le score)\n",
    "     similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "     similar_movies = [df_selection['tconst'].iloc[i[0]] for i in similarity_scores[1:10]]\n",
    "\n",
    "     return similarity_scores\n",
    "\n",
    "     \n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Faire un test avec lemmarizing (garder les mots en 'binômes')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommandation2(tconst):\n",
    "    index = df_test.index\n",
    "    df_test_num = df_test.select_dtypes('number')\n",
    "    df_test_cat = df_test.select_dtypes(['object', 'category', 'string', 'bool'])\n",
    "\n",
    "    # Normalize numerical columns\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    SN = MinMaxScaler()\n",
    "    df_test_num_SN = pd.DataFrame(SN.fit_transform(df_test_num), columns=df_test_num.columns, index=index)\n",
    "\n",
    "    # Encode categorical columns\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    df_test_cat_encoded = df_test_cat.copy()\n",
    "    \n",
    "    for col in df_test_cat_encoded.columns:\n",
    "        le = LabelEncoder()\n",
    "        df_test_cat_encoded[col] = le.fit_transform(df_test_cat_encoded[col].fillna('unknown'))\n",
    "        \n",
    "\n",
    "    # Combine numeric and encoded data\n",
    "    df_test_encoded = pd.concat([df_test_num_SN, df_test_cat_encoded], axis=1)\n",
    "    df_test_encoded['tconst'] = df_test['tconst']  # Add 'tconst' back if it was dropped\n",
    "\n",
    "    # List of features\n",
    "    caracteristiques = df_test_encoded.columns.drop(\n",
    "        ['tconst', 'title', 'tmdb_popularity', 'title_ratings_numVotes', 'imdb_id', 'genres', 'overview', 'tmdb_US',\n",
    "          'tmdb_FR', 'tmdb_GB', 'tmdb_DE', 'tmdb_JP', 'tmdb_IN', 'tmdb_IT',\n",
    "          'tmdb_CA', 'tmdb_ES', 'tmdb_MX', 'tmdb_HK', 'tmdb_BR', 'tmdb_SE',\n",
    "          'tmdb_SU', 'tmdb_PH', 'tmdb_KR', 'tmdb_AU', 'tmdb_CN', 'tmdb_AR',\n",
    "          'tmdb_RU', 'tmdb_DK', 'tmdb_NL', 'tmdb_BE', 'tmdb_AT', 'tmdb_TR',\n",
    "          'tmdb_PL', 'tmdb_CH', 'tmdb_XC', 'tmdb_FI', 'tmdb_NO', 'tmdb_IR',\n",
    "          'tmdb_XG', 'tmdb_EG', 'tmdb_NG', 'tmdb_ZA']\n",
    "    )\n",
    "\n",
    "    # Split into \"good\" and \"bad\" films\n",
    "    bons_films = df_test_encoded[df_test_encoded['notes'] >= 0.7]\n",
    "\n",
    "    # Check if tconst exists\n",
    "    if tconst not in df_test_encoded['tconst'].values:\n",
    "        raise ValueError(f\"tconst {tconst} not found in the dataset.\")\n",
    "\n",
    "    # Select features for the requested film\n",
    "    caract_film = df_test_encoded[df_test_encoded['tconst'] == tconst][caracteristiques]\n",
    "\n",
    "    # NearestNeighbors model\n",
    "    from sklearn.neighbors import NearestNeighbors\n",
    "    model = NearestNeighbors(n_neighbors=1000, metric='euclidean')\n",
    "    model.fit(bons_films[caracteristiques])\n",
    "\n",
    "    distances, indices = model.kneighbors(caract_film)\n",
    "\n",
    "    # Select films found\n",
    "    colonnes = ['tconst', 'genres', 'overview', 'nconst']\n",
    "    selection = bons_films.iloc[indices[0]][colonnes]\n",
    "    df_selection = pd.DataFrame(selection).reset_index()\n",
    "\n",
    "    # Director weighting\n",
    "    target_directors = df_test.loc[df_test['tconst'] == tconst, 'nconst'].unique()\n",
    "    df_selection['director_match'] = df_selection['nconst'].apply(\n",
    "        lambda x: 1 if x in target_directors else 0\n",
    "    )\n",
    "\n",
    "    # Weighted column for text\n",
    "    colonnes_poids = {\n",
    "        'tconst': 1,\n",
    "        'genres': 1,\n",
    "        'overview': 15,\n",
    "        'nconst': 1\n",
    "    }\n",
    "\n",
    "    df_tfidf = df_selection.copy()\n",
    "    df_tfidf['texte'] = df_selection.apply(\n",
    "        lambda ligne: ' '.join(\n",
    "            (str(ligne[col]) + ' ') * poids for col, poids in colonnes_poids.items()\n",
    "        ),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # TF-IDF and cosine similarity\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', max_df=0.8)\n",
    "    df_tfidf_matrix = vectorizer.fit_transform(df_tfidf['texte'])\n",
    "\n",
    "    similarite = cosine_similarity(df_tfidf_matrix)\n",
    "    similarity_scores = list(enumerate(similarite[0]))\n",
    "    similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    similar_movies = [df_selection['tconst'].iloc[i[0]] for i in similarity_scores[1:10]]\n",
    "\n",
    "    return similar_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tt0482571',\n",
       " 'tt15398776',\n",
       " 'tt0154506',\n",
       " 'tt0278504',\n",
       " 'tt0372784',\n",
       " 'tt5013056',\n",
       " 'tt0816692',\n",
       " 'tt6723592',\n",
       " 'tt0468569']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selection2 = recommandation2('tt1375666')\n",
    "selection2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Pour la prochaine fois : utiliser df_selection pour le TFIDF et ne pas avoir les 300K lignes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tt15398776',\n",
       " 'tt0154506',\n",
       " 'tt0482571',\n",
       " 'tt0278504',\n",
       " 'tt0372784',\n",
       " 'tt5013056',\n",
       " 'tt0816692',\n",
       " 'tt6723592',\n",
       " 'tt0468569']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "['tt15398776', 'tt0154506', 'tt0482571', 'tt0278504', 'tt0372784', 'tt5013056', 'tt0816692', 'tt6723592', 'tt0468569']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_lg')\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[199], line 27\u001b[0m\n\u001b[0;32m     23\u001b[0m             texte_lem \u001b[38;5;241m=\u001b[39m texte_lem \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m mot\n\u001b[0;32m     25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m texte_lem\n\u001b[1;32m---> 27\u001b[0m df_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moverview_lem\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moverview\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(lemma)\n",
      "File \u001b[1;32mc:\\Users\\frale\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4800\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\n\u001b[0;32m   4918\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4919\u001b[0m         func,\n\u001b[0;32m   4920\u001b[0m         convert_dtype\u001b[38;5;241m=\u001b[39mconvert_dtype,\n\u001b[0;32m   4921\u001b[0m         by_row\u001b[38;5;241m=\u001b[39mby_row,\n\u001b[0;32m   4922\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m   4923\u001b[0m         kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m-> 4924\u001b[0m     )\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[1;32mc:\\Users\\frale\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\frale\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_map_values(\n\u001b[0;32m   1508\u001b[0m     mapper\u001b[38;5;241m=\u001b[39mcurried, na_action\u001b[38;5;241m=\u001b[39maction, convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype\n\u001b[0;32m   1509\u001b[0m )\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\frale\\anaconda3\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m algorithms\u001b[38;5;241m.\u001b[39mmap_array(arr, mapper, na_action\u001b[38;5;241m=\u001b[39mna_action, convert\u001b[38;5;241m=\u001b[39mconvert)\n",
      "File \u001b[1;32mc:\\Users\\frale\\anaconda3\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer(values, mapper, convert\u001b[38;5;241m=\u001b[39mconvert)\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[199], line 10\u001b[0m, in \u001b[0;36mlemma\u001b[1;34m(texte)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlemma\u001b[39m (texte):\n\u001b[1;32m---> 10\u001b[0m         texte_tokens \u001b[38;5;241m=\u001b[39m nlp(texte\u001b[38;5;241m.\u001b[39mlower())\n\u001b[0;32m     12\u001b[0m         lemma \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     14\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m mot \u001b[38;5;129;01min\u001b[39;00m texte_tokens:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'float' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('popular', quiet=True)\n",
    "nltk.download('punkt_tab', quiet=True)\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "!python -m spacy download en_core_web_lg --quiet\n",
    "nlp = spacy.load('en_core_web_lg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301086/301086 [26:54<00:00, 186.44it/s] \n"
     ]
    }
   ],
   "source": [
    "'''from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# On crée une fonction lemmatizing sur le df global pour ne pas avoir à le faire à chaque fois sur le Streamlit\n",
    "def lemma (texte):\n",
    "        texte_tokens = nlp(str(texte).lower())\n",
    "\n",
    "        lemma = []\n",
    "\n",
    "        for mot in texte_tokens:\n",
    "            if str(mot).isalpha() == True:\n",
    "                lemma.append(mot.lemma_)\n",
    "\n",
    "        sw = stopwords.words('english')\n",
    "   \n",
    "        tokens_propres = [mot for mot in lemma if mot not in sw]\n",
    "        texte_lem = \"\"\n",
    "        for mot in tokens_propres:\n",
    "            texte_lem = texte_lem + \" \" + mot\n",
    "            \n",
    "        return texte_lem\n",
    "\n",
    "df_test['overview_lem'] = df_test['overview'].progress_apply(lemma)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['tmdb_US', 'tmdb_FR', 'tmdb_GB', 'tmdb_DE', 'tmdb_JP', 'tmdb_IN', 'tmdb_IT', 'tmdb_CA', 'tmdb_ES', 'tmdb_MX', 'tmdb_HK', 'tmdb_BR', 'tmdb_SE', 'tmdb_SU', 'tmdb_PH', 'tmdb_KR', 'tmdb_AU', 'tmdb_CN', 'tmdb_AR', 'tmdb_RU', 'tmdb_DK', 'tmdb_NL', 'tmdb_BE', 'tmdb_AT', 'tmdb_TR', 'tmdb_PL', 'tmdb_CH', 'tmdb_XC', 'tmdb_FI', 'tmdb_NO', 'tmdb_IR', 'tmdb_XG', 'tmdb_EG', 'tmdb_NG', 'tmdb_ZA'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[284], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_test \u001b[38;5;241m=\u001b[39m df_test\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtmdb_US\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtmdb_FR\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtmdb_GB\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtmdb_DE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtmdb_JP\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtmdb_IN\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtmdb_IT\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      2\u001b[0m  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtmdb_CA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtmdb_ES\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtmdb_MX\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtmdb_HK\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtmdb_BR\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtmdb_SE\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      3\u001b[0m  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtmdb_SU\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtmdb_PH\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtmdb_KR\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtmdb_AU\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtmdb_CN\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtmdb_AR\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      4\u001b[0m  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtmdb_RU\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtmdb_DK\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtmdb_NL\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtmdb_BE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtmdb_AT\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtmdb_TR\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      5\u001b[0m  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtmdb_PL\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtmdb_CH\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtmdb_XC\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtmdb_FI\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtmdb_NO\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtmdb_IR\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      6\u001b[0m  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtmdb_XG\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtmdb_EG\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtmdb_NG\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtmdb_ZA\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\frale\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:5581\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5434\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5435\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5442\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5443\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5444\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5445\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5446\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5579\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5580\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mdrop(\n\u001b[0;32m   5582\u001b[0m         labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[0;32m   5583\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   5584\u001b[0m         index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m   5585\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   5586\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[0;32m   5587\u001b[0m         inplace\u001b[38;5;241m=\u001b[39minplace,\n\u001b[0;32m   5588\u001b[0m         errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m   5589\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\frale\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:4788\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4786\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4788\u001b[0m         obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_drop_axis(labels, axis, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32mc:\\Users\\frale\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:4830\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4828\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4829\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4830\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4831\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4833\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4834\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\frale\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7070\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   7068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   7069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 7070\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   7071\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   7072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['tmdb_US', 'tmdb_FR', 'tmdb_GB', 'tmdb_DE', 'tmdb_JP', 'tmdb_IN', 'tmdb_IT', 'tmdb_CA', 'tmdb_ES', 'tmdb_MX', 'tmdb_HK', 'tmdb_BR', 'tmdb_SE', 'tmdb_SU', 'tmdb_PH', 'tmdb_KR', 'tmdb_AU', 'tmdb_CN', 'tmdb_AR', 'tmdb_RU', 'tmdb_DK', 'tmdb_NL', 'tmdb_BE', 'tmdb_AT', 'tmdb_TR', 'tmdb_PL', 'tmdb_CH', 'tmdb_XC', 'tmdb_FI', 'tmdb_NO', 'tmdb_IR', 'tmdb_XG', 'tmdb_EG', 'tmdb_NG', 'tmdb_ZA'] not found in axis\""
     ]
    }
   ],
   "source": [
    "'''df_test = df_test.drop(columns=['tmdb_US','tmdb_FR', 'tmdb_GB', 'tmdb_DE', 'tmdb_JP', 'tmdb_IN', 'tmdb_IT',\n",
    " 'tmdb_CA', 'tmdb_ES', 'tmdb_MX', 'tmdb_HK', 'tmdb_BR', 'tmdb_SE',\n",
    " 'tmdb_SU', 'tmdb_PH', 'tmdb_KR', 'tmdb_AU', 'tmdb_CN', 'tmdb_AR',\n",
    " 'tmdb_RU', 'tmdb_DK', 'tmdb_NL', 'tmdb_BE', 'tmdb_AT', 'tmdb_TR',\n",
    " 'tmdb_PL', 'tmdb_CH', 'tmdb_XC', 'tmdb_FI', 'tmdb_NO', 'tmdb_IR',\n",
    " 'tmdb_XG', 'tmdb_EG', 'tmdb_NG', 'tmdb_ZA'])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''export = \"../machine learning/DF_ML.csv.gz\"\n",
    "df_test.to_csv(export, sep=\",\", index=False, compression=\"gzip\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = \"../machine learning/DF_ML.csv.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommandation6(tconst):\n",
    "    \n",
    "    # ----------------------------------------------------------\n",
    "    # Préparation des données\n",
    "    # ----------------------------------------------------------\n",
    "\n",
    "    index = df_test.index\n",
    "    df_test_num = df_test.select_dtypes('number')\n",
    "    df_test_cat = df_test.select_dtypes(['object', 'category', 'string', 'bool'])\n",
    "\n",
    "    # Normalisation des colonnes numériques\n",
    "    SN = MinMaxScaler()\n",
    "    df_test_num_SN = pd.DataFrame(SN.fit_transform(df_test_num), columns=df_test_num.columns, index=index)\n",
    "\n",
    "    # Encodage uniquement de la colonne 'nconst'\n",
    "    df_test_cat_encoded = df_test_cat.copy()\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    le = LabelEncoder()\n",
    "    df_test_cat_encoded['nconst'] = le.fit_transform(df_test_cat_encoded['nconst'].fillna('inconnu'))\n",
    "\n",
    "    # On assemble le df numérique et le df texte\n",
    "    df_test_encoded = pd.concat([df_test_num_SN, df_test_cat_encoded], axis=1)\n",
    "\n",
    "    #On sépare notre df en deux groupes, en fonction de la note\n",
    "    bons_films = df_test_encoded[df_test_encoded['notes'] >= 0.7]\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    # KNN sur les caractéristiques numériques\n",
    "    # ----------------------------------------------------------\n",
    "\n",
    "    colonnes_a_exclure = ['tconst', 'title', 'tmdb_popularity', 'title_ratings_numVotes', 'imdb_id', 'genres', 'overview', 'overview_lem']\n",
    "    caracteristiques = df_test_encoded.columns.drop(colonnes_a_exclure, errors='ignore')\n",
    "\n",
    "    model = NearestNeighbors(n_neighbors=1000, metric='euclidean') # Il faudra tester d'autres combinaisons\n",
    "    model.fit(bons_films[caracteristiques])\n",
    "\n",
    "    caract_film = df_test_encoded[df_test_encoded['tconst'] == tconst][caracteristiques]\n",
    "    distances, indices = model.kneighbors(caract_film)\n",
    "\n",
    "    if not df_test_encoded[(df_test_encoded['tconst'] == tconst) & (df_test_encoded['notes'] >= 0.7)].empty:\n",
    "        selection = bons_films.iloc[indices[0]].copy()\n",
    "        selection['distance_knn'] = distances[0]\n",
    "    else:\n",
    "        selection = bons_films.iloc[indices[0]].copy()\n",
    "        selection = pd.concat([df_test_encoded[df_test_encoded['tconst'] == tconst], selection.iloc[:-1]], axis=0)\n",
    "        selection['distance_knn'] = distances[0]\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    # TF-IDF avec lemmatisation\n",
    "    # ----------------------------------------------------------\n",
    "\n",
    "    colonnes_poids = {\n",
    "        'genres': 1,\n",
    "        'overview_lem': 1,\n",
    "        'nconst': 1\n",
    "    }\n",
    "\n",
    "    # On crée une colonne 'texte' qui combine les valeurs pondérées des colonnes spécifiées\n",
    "    selection['texte'] = selection.apply(lambda row: \n",
    "        ' '.join([\n",
    "            (str(row[col]) + ' ') * colonnes_poids.get(col, 1)  # Répète la valeur de la colonne selon son poids\n",
    "            for col in colonnes_poids.keys()\n",
    "        ]),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', max_df=0.8)\n",
    "    tfidf_matrix = vectorizer.fit_transform(selection['texte'])\n",
    "\n",
    "    model_tfidf = NearestNeighbors(n_neighbors=1000, metric='cosine')\n",
    "    model_tfidf.fit(tfidf_matrix)\n",
    "\n",
    "    distances_tfidf, indices_tfidf = model_tfidf.kneighbors(tfidf_matrix[0])\n",
    "    selection['distance_tfidf'] = distances_tfidf[0]\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    # Moyenne pondérée des distances\n",
    "    # ----------------------------------------------------------\n",
    "\n",
    "    poids_knn = 1\n",
    "    poids_tfidf = 100\n",
    "\n",
    "    selection['distance_ponderee'] = (\n",
    "        poids_knn * selection['distance_knn']) + (poids_tfidf * selection['distance_tfidf']\n",
    "    ) \n",
    "\n",
    "    # Tri final par la distance pondérée\n",
    "    selection = selection.sort_values(by='distance_ponderee')\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    # Résultat final\n",
    "    # ----------------------------------------------------------\n",
    "\n",
    "    return selection[['title', 'tconst', 'distance_knn', 'distance_tfidf', 'distance_ponderee', 'overview_lem', 'texte']].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>tconst</th>\n",
       "      <th>distance_knn</th>\n",
       "      <th>distance_tfidf</th>\n",
       "      <th>distance_ponderee</th>\n",
       "      <th>overview_lem</th>\n",
       "      <th>texte</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58870</th>\n",
       "      <td>Home Alone 2: Lost in New York</td>\n",
       "      <td>tt0104431</td>\n",
       "      <td>1.732189</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.732189</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Comedy', 'Family', 'Adventure']  nan  333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60538</th>\n",
       "      <td>Mrs. Doubtfire</td>\n",
       "      <td>tt0107614</td>\n",
       "      <td>1.733963</td>\n",
       "      <td>0.585894</td>\n",
       "      <td>60.323389</td>\n",
       "      <td>love irresponsible dad daniel hillard estrang...</td>\n",
       "      <td>['Comedy', 'Drama', 'Family']   love irrespons...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56431</th>\n",
       "      <td>Home Alone</td>\n",
       "      <td>tt0099785</td>\n",
       "      <td>2.237958</td>\n",
       "      <td>0.599287</td>\n",
       "      <td>62.166670</td>\n",
       "      <td>eight year old kevin mccallister make situati...</td>\n",
       "      <td>['Comedy', 'Family']   eight year old kevin mc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106890</th>\n",
       "      <td>Harry Potter and the Chamber of Secrets</td>\n",
       "      <td>tt0295297</td>\n",
       "      <td>2.238258</td>\n",
       "      <td>0.601103</td>\n",
       "      <td>62.348586</td>\n",
       "      <td>car fly tree fight back mysterious house elf ...</td>\n",
       "      <td>['Adventure', 'Fantasy']   car fly tree fight ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94835</th>\n",
       "      <td>Harry Potter and the Sorcerer's Stone</td>\n",
       "      <td>tt0241527</td>\n",
       "      <td>2.451199</td>\n",
       "      <td>0.601103</td>\n",
       "      <td>62.561527</td>\n",
       "      <td>harry potter live stair aunt uncle house whol...</td>\n",
       "      <td>['Adventure', 'Fantasy']   harry potter live s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95186</th>\n",
       "      <td>The Man Who Wasn't There</td>\n",
       "      <td>tt0243133</td>\n",
       "      <td>2.837149</td>\n",
       "      <td>0.601103</td>\n",
       "      <td>62.947478</td>\n",
       "      <td>tale murder crime punishment set summer ed cr...</td>\n",
       "      <td>['Crime', 'Drama']   tale murder crime punishm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141467</th>\n",
       "      <td>The Tragedy of Macbeth</td>\n",
       "      <td>tt10095582</td>\n",
       "      <td>3.742161</td>\n",
       "      <td>0.603097</td>\n",
       "      <td>64.051867</td>\n",
       "      <td>macbeth thane glamis receive prophecy trio wi...</td>\n",
       "      <td>['Drama', 'War']   macbeth thane glamis receiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75774</th>\n",
       "      <td>The Virgin Suicides</td>\n",
       "      <td>tt0159097</td>\n",
       "      <td>3.743455</td>\n",
       "      <td>0.603097</td>\n",
       "      <td>64.053160</td>\n",
       "      <td>group male friend become obsess five mysterio...</td>\n",
       "      <td>['Drama', 'Romance']   group male friend becom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113551</th>\n",
       "      <td>Lost in Translation</td>\n",
       "      <td>tt0335266</td>\n",
       "      <td>3.933236</td>\n",
       "      <td>0.603097</td>\n",
       "      <td>64.242942</td>\n",
       "      <td>two lose soul visit tokyo young neglect wife ...</td>\n",
       "      <td>['Drama', 'Romance', 'Comedy']   two lose soul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43580</th>\n",
       "      <td>The Deer Hunter</td>\n",
       "      <td>tt0077416</td>\n",
       "      <td>5.386922</td>\n",
       "      <td>0.603097</td>\n",
       "      <td>65.696628</td>\n",
       "      <td>group work class friend decide enlist army vi...</td>\n",
       "      <td>['Drama', 'War']   group work class friend dec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          title      tconst  distance_knn  \\\n",
       "58870            Home Alone 2: Lost in New York   tt0104431      1.732189   \n",
       "60538                            Mrs. Doubtfire   tt0107614      1.733963   \n",
       "56431                                Home Alone   tt0099785      2.237958   \n",
       "106890  Harry Potter and the Chamber of Secrets   tt0295297      2.238258   \n",
       "94835     Harry Potter and the Sorcerer's Stone   tt0241527      2.451199   \n",
       "95186                  The Man Who Wasn't There   tt0243133      2.837149   \n",
       "141467                   The Tragedy of Macbeth  tt10095582      3.742161   \n",
       "75774                       The Virgin Suicides   tt0159097      3.743455   \n",
       "113551                      Lost in Translation   tt0335266      3.933236   \n",
       "43580                           The Deer Hunter   tt0077416      5.386922   \n",
       "\n",
       "        distance_tfidf  distance_ponderee  \\\n",
       "58870         0.000000           1.732189   \n",
       "60538         0.585894          60.323389   \n",
       "56431         0.599287          62.166670   \n",
       "106890        0.601103          62.348586   \n",
       "94835         0.601103          62.561527   \n",
       "95186         0.601103          62.947478   \n",
       "141467        0.603097          64.051867   \n",
       "75774         0.603097          64.053160   \n",
       "113551        0.603097          64.242942   \n",
       "43580         0.603097          65.696628   \n",
       "\n",
       "                                             overview_lem  \\\n",
       "58870                                                 NaN   \n",
       "60538    love irresponsible dad daniel hillard estrang...   \n",
       "56431    eight year old kevin mccallister make situati...   \n",
       "106890   car fly tree fight back mysterious house elf ...   \n",
       "94835    harry potter live stair aunt uncle house whol...   \n",
       "95186    tale murder crime punishment set summer ed cr...   \n",
       "141467   macbeth thane glamis receive prophecy trio wi...   \n",
       "75774    group male friend become obsess five mysterio...   \n",
       "113551   two lose soul visit tokyo young neglect wife ...   \n",
       "43580    group work class friend decide enlist army vi...   \n",
       "\n",
       "                                                    texte  \n",
       "58870        ['Comedy', 'Family', 'Adventure']  nan  333   \n",
       "60538   ['Comedy', 'Drama', 'Family']   love irrespons...  \n",
       "56431   ['Comedy', 'Family']   eight year old kevin mc...  \n",
       "106890  ['Adventure', 'Fantasy']   car fly tree fight ...  \n",
       "94835   ['Adventure', 'Fantasy']   harry potter live s...  \n",
       "95186   ['Crime', 'Drama']   tale murder crime punishm...  \n",
       "141467  ['Drama', 'War']   macbeth thane glamis receiv...  \n",
       "75774   ['Drama', 'Romance']   group male friend becom...  \n",
       "113551  ['Drama', 'Romance', 'Comedy']   two lose soul...  \n",
       "43580   ['Drama', 'War']   group work class friend dec...  "
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selection2 = recommandation6('tt0104431')\n",
    "selection2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "import spacy\n",
    "\n",
    "# Charger le modèle Spacy pour la lemmatisation\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def recommandation6(tconst):\n",
    "    # ----------------------------------------------------------\n",
    "    # Préparation des données\n",
    "    # ----------------------------------------------------------\n",
    "    index = df_test.index\n",
    "    df_test_num = df_test.select_dtypes('number')\n",
    "    df_test_cat = df_test.select_dtypes(['object', 'category', 'string', 'bool'])\n",
    "\n",
    "    # Normalisation des colonnes numériques\n",
    "    SN = MinMaxScaler()\n",
    "    df_test_num_SN = pd.DataFrame(SN.fit_transform(df_test_num), columns=df_test_num.columns, index=index)\n",
    "\n",
    "    # Encodage uniquement de la colonne 'nconst'\n",
    "    df_test_cat_encoded = df_test_cat.copy()\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    le = LabelEncoder()\n",
    "    df_test_cat_encoded['nconst'] = le.fit_transform(df_test_cat_encoded['nconst'].fillna('inconnu'))\n",
    "\n",
    "    # On assemble le df numérique et le df texte\n",
    "    df_test_encoded = pd.concat([df_test_num_SN, df_test_cat_encoded], axis=1)\n",
    "\n",
    "    #On sépare notre df en deux groupes, en fonction de la note\n",
    "    bons_films = df_test_encoded[df_test_encoded['notes'] >= 0.7]\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    # KNN sur les caractéristiques numériques\n",
    "    # ----------------------------------------------------------\n",
    "    colonnes_a_exclure = ['tconst', 'title', 'tmdb_popularity', 'title_ratings_numVotes', 'imdb_id', 'genres', 'overview', 'tmdb_US',\n",
    "          'tmdb_FR', 'tmdb_GB', 'tmdb_DE', 'tmdb_JP', 'tmdb_IN', 'tmdb_IT',\n",
    "          'tmdb_CA', 'tmdb_ES', 'tmdb_MX', 'tmdb_HK', 'tmdb_BR', 'tmdb_SE',\n",
    "          'tmdb_SU', 'tmdb_PH', 'tmdb_KR', 'tmdb_AU', 'tmdb_CN', 'tmdb_AR',\n",
    "          'tmdb_RU', 'tmdb_DK', 'tmdb_NL', 'tmdb_BE', 'tmdb_AT', 'tmdb_TR',\n",
    "          'tmdb_PL', 'tmdb_CH', 'tmdb_XC', 'tmdb_FI', 'tmdb_NO', 'tmdb_IR',\n",
    "          'tmdb_XG', 'tmdb_EG', 'tmdb_NG', 'tmdb_ZA']\n",
    "    caracteristiques = df_test_encoded.columns.drop(colonnes_a_exclure, errors='ignore')\n",
    "\n",
    "    model = NearestNeighbors(n_neighbors=1000, metric='euclidean') # Il faudra tester d'autres combinaisons\n",
    "    model.fit(bons_films[caracteristiques])\n",
    "\n",
    "    caract_film = df_test_encoded[df_test_encoded['tconst'] == tconst][caracteristiques]\n",
    "    distances, indices = model.kneighbors(caract_film)\n",
    "\n",
    "    selection = bons_films.iloc[indices[0]].copy()\n",
    "    selection['distance_knn'] = distances[0]\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    # TF-IDF avec lemmatisation\n",
    "    # ----------------------------------------------------------\n",
    "    def lemmatize_text(text):\n",
    "        doc = nlp(str(text))\n",
    "        return \" \".join([token.lemma_ for token in doc if token.is_alpha and token.text not in ENGLISH_STOP_WORDS])\n",
    "\n",
    "    selection['overview_lem'] = selection['overview'].apply(lemmatize_text)\n",
    "\n",
    "    colonnes_poids = {\n",
    "        'genres': 1,\n",
    "        'overview_lem': 1,\n",
    "        'nconst': 1\n",
    "    }\n",
    "\n",
    "    # On crée une colonne 'texte' qui combine les valeurs pondérées des colonnes spécifiées\n",
    "    selection['texte'] = selection.apply(lambda row: \n",
    "        ' '.join([\n",
    "            (str(row[col]) + ' ') * colonnes_poids.get(col, 1)  # Répète la valeur de la colonne selon son poids\n",
    "            for col in colonnes_poids.keys()\n",
    "        ]),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', max_df=0.8)\n",
    "    tfidf_matrix = vectorizer.fit_transform(selection['texte'])\n",
    "\n",
    "    model_tfidf = NearestNeighbors(n_neighbors=1000, metric='cosine')\n",
    "    model_tfidf.fit(tfidf_matrix)\n",
    "\n",
    "    distances_tfidf, indices_tfidf = model_tfidf.kneighbors(tfidf_matrix[0])\n",
    "\n",
    "    selection['distance_tfidf'] = distances_tfidf[0]\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    # Moyenne pondérée des distances\n",
    "    # ----------------------------------------------------------\n",
    "    poids_knn = 1\n",
    "    poids_tfidf = 100\n",
    "\n",
    "    selection['distance_ponderee'] = (\n",
    "        poids_knn * selection['distance_knn']) * (poids_tfidf * selection['distance_tfidf']\n",
    "    ) \n",
    "\n",
    "    # Tri final par la distance pondérée\n",
    "    selection = selection.sort_values(by='distance_ponderee')\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    # Résultat final\n",
    "    # ----------------------------------------------------------\n",
    "    return selection[['title', 'tconst', 'distance_knn', 'distance_tfidf', 'distance_ponderee', 'overview_lem', 'texte']].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "      <th>startYear</th>\n",
       "      <th>runtimeMinutes</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Biography</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>...</th>\n",
       "      <th>tmdb_FI</th>\n",
       "      <th>tmdb_NO</th>\n",
       "      <th>tmdb_IR</th>\n",
       "      <th>tmdb_XG</th>\n",
       "      <th>tmdb_EG</th>\n",
       "      <th>tmdb_NG</th>\n",
       "      <th>tmdb_ZA</th>\n",
       "      <th>rating</th>\n",
       "      <th>nconst</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [tconst, startYear, runtimeMinutes, Action, Adventure, Animation, Biography, Comedy, Crime, Documentary, Drama, Family, Fantasy, Game-Show, History, Horror, Music, Musical, Mystery, News, Reality-TV, Romance, Sci-Fi, Sport, Talk-Show, Thriller, War, Western, title_ratings_numVotes, title, tmdb_popularity, tmdb_US, tmdb_FR, tmdb_GB, tmdb_DE, tmdb_JP, tmdb_IN, tmdb_IT, tmdb_CA, tmdb_ES, tmdb_MX, tmdb_HK, tmdb_BR, tmdb_SE, tmdb_SU, tmdb_PH, tmdb_KR, tmdb_AU, tmdb_CN, tmdb_AR, tmdb_RU, tmdb_DK, tmdb_NL, tmdb_BE, tmdb_AT, tmdb_TR, tmdb_PL, tmdb_CH, tmdb_XC, tmdb_FI, tmdb_NO, tmdb_IR, tmdb_XG, tmdb_EG, tmdb_NG, tmdb_ZA, rating, nconst, notes]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 69 columns]"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ml[df_ml['tconst'] == 'tt28324464']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommandation(tconst):\n",
    "    \n",
    "    # ----------------------------------------------------------\n",
    "    # Préparation des données\n",
    "    # ----------------------------------------------------------\n",
    "\n",
    "    index = df_test.index\n",
    "    df_test_num = df_test.select_dtypes('number')\n",
    "    df_test_cat = df_test.select_dtypes(['object', 'category', 'string', 'bool'])\n",
    "\n",
    "    # Normalisation des colonnes numériques\n",
    "    SN = MinMaxScaler()\n",
    "    df_test_num_SN = pd.DataFrame(SN.fit_transform(df_test_num), columns=df_test_num.columns, index=index)\n",
    "\n",
    "    # Encodage uniquement de la colonne 'nconst'\n",
    "    df_test_cat_encoded = df_test_cat.copy()\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    le = LabelEncoder()\n",
    "    df_test_cat_encoded['nconst'] = le.fit_transform(df_test_cat_encoded['nconst'].fillna('inconnu'))\n",
    "\n",
    "    # On assemble le df numérique et le df texte\n",
    "    df_test_encoded = pd.concat([df_test_num_SN, df_test_cat_encoded], axis=1)\n",
    "\n",
    "    #On sépare notre df en deux groupes, en fonction de la note\n",
    "    bons_films = df_test_encoded[df_test_encoded['notes'] >= 0.7]\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    # KNN sur les caractéristiques numériques\n",
    "    # ----------------------------------------------------------\n",
    "\n",
    "    colonnes_a_exclure = ['tconst', 'title', 'tmdb_popularity', 'title_ratings_numVotes', 'imdb_id', 'genres', 'overview', 'overview_lem']\n",
    "    caracteristiques = df_test_encoded.columns.drop(colonnes_a_exclure, errors='ignore')\n",
    "\n",
    "    model = NearestNeighbors(n_neighbors=1000, metric='euclidean') # Il faudra tester d'autres combinaisons\n",
    "    model.fit(bons_films[caracteristiques])\n",
    "\n",
    "    caract_film = df_test_encoded[df_test_encoded['tconst'] == tconst][caracteristiques]\n",
    "    distances, indices = model.kneighbors(caract_film)\n",
    "\n",
    "    if not df_test_encoded[(df_test_encoded['tconst'] == tconst) & (df_test_encoded['notes'] >= 0.7)].empty:\n",
    "        selection = bons_films.iloc[indices[0]].copy()\n",
    "        selection['distance_knn'] = distances[0]\n",
    "    else:\n",
    "        selection = bons_films.iloc[indices[0]].copy()\n",
    "        selection = pd.concat([df_test_encoded[df_test_encoded['tconst'] == tconst], selection.iloc[:-1]], axis=0)\n",
    "        selection['distance_knn'] = distances[0]\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    # TF-IDF avec lemmatisation\n",
    "    # ----------------------------------------------------------\n",
    "\n",
    "    colonnes_poids = {\n",
    "        'genres': 1,\n",
    "        'overview_lem': 1,\n",
    "        'nconst': 1\n",
    "    }\n",
    "\n",
    "    # On crée une colonne 'texte' qui combine les valeurs pondérées des colonnes spécifiées\n",
    "    selection['texte'] = selection.apply(lambda row: \n",
    "        ' '.join([\n",
    "            (str(row[col]) + ' ') * colonnes_poids.get(col, 1)  # Répète la valeur de la colonne selon son poids\n",
    "            for col in colonnes_poids.keys()\n",
    "        ]),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', max_df=0.8)\n",
    "    tfidf_matrix = vectorizer.fit_transform(selection['texte'])\n",
    "\n",
    "    model_tfidf = NearestNeighbors(n_neighbors=1000, metric='cosine')\n",
    "    model_tfidf.fit(tfidf_matrix)\n",
    "\n",
    "    distances_tfidf, indices_tfidf = model_tfidf.kneighbors(tfidf_matrix[0])\n",
    "    selection['distance_tfidf'] = distances_tfidf[0]\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    # Moyenne pondérée des distances\n",
    "    # ----------------------------------------------------------\n",
    "\n",
    "    poids_knn = 1\n",
    "    poids_tfidf = 100\n",
    "\n",
    "    selection['distance_ponderee'] = (\n",
    "        poids_knn * selection['distance_knn']) + (poids_tfidf * selection['distance_tfidf']\n",
    "    ) \n",
    "\n",
    "    # Tri final par la distance pondérée\n",
    "    selection = selection.sort_values(by='distance_ponderee')\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    # Résultat final\n",
    "    # ----------------------------------------------------------\n",
    "    selection_finale = pd.DataFrame(selection['tconst'][1:11]).reset_index(drop=True)\n",
    "\n",
    "    return selection_finale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0107614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0241527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0295297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0243133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt10095582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tt0335266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tt0159097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tt0077416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tt0083652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tt0115005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tconst\n",
       "0   tt0107614\n",
       "1   tt0241527\n",
       "2   tt0295297\n",
       "3   tt0243133\n",
       "4  tt10095582\n",
       "5   tt0335266\n",
       "6   tt0159097\n",
       "7   tt0077416\n",
       "8   tt0083652\n",
       "9   tt0115005"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommandation('tt0099785')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
